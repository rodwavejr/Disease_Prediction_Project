{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Classification Dataset Preparation\n",
    "\n",
    "This notebook prepares a master dataset for the COVID-19 classification stage of our pipeline, combining data from:\n",
    "\n",
    "1. **CDC COVID-19 Case Surveillance Data**: For confirmed COVID-19 cases\n",
    "2. **MIMIC-IV Clinical Data**: For hospital and ICU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Make sure processed directory exists\n",
    "os.makedirs('../data/processed', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load CDC Data\n",
    "\n",
    "First, let's load the CDC COVID-19 case surveillance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "cdc_file = '../data/external/covid19_case_surveillance.csv'\n",
    "\n",
    "# Check if file exists\n",
    "if os.path.exists(cdc_file):\n",
    "    # Load data, handling the issue with space in column name\n",
    "    cdc_df = pd.read_csv(cdc_file, skipinitialspace=True)\n",
    "    \n",
    "    # Strip whitespace from column names to be safe\n",
    "    cdc_df.columns = cdc_df.columns.str.strip()\n",
    "    \n",
    "    print(f\"Loaded {len(cdc_df)} CDC records\")\n",
    "    cdc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check CDC Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "print(\"CDC data columns:\")\n",
    "for col in cdc_df.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# Check COVID status distribution\n",
    "print(\"\\nCOVID-19 Status Distribution:\")\n",
    "display(cdc_df['current_status'].value_counts())\n",
    "\n",
    "# Basic visualizations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='current_status', data=cdc_df)\n",
    "plt.title('COVID-19 Status')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load MIMIC Data\n",
    "\n",
    "Now let's load MIMIC-IV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "mimic_dir = '../data/external/mimic'\n",
    "patients_file = os.path.join(mimic_dir, 'patients_sample.csv')\n",
    "diagnoses_file = os.path.join(mimic_dir, 'relevant_diagnoses.csv')\n",
    "icd_file = os.path.join(mimic_dir, 'd_icd_diagnoses.csv')\n",
    "labs_file = os.path.join(mimic_dir, 'relevant_labevents.csv')\n",
    "\n",
    "# Load patient data\n",
    "mimic_patients = None\n",
    "if os.path.exists(patients_file):\n",
    "    mimic_patients = pd.read_csv(patients_file)\n",
    "    print(f\"Loaded {len(mimic_patients)} MIMIC patient records\")\n",
    "    display(mimic_patients.head())\n",
    "\n",
    "# Load diagnoses data\n",
    "mimic_diagnoses = None\n",
    "if os.path.exists(diagnoses_file):\n",
    "    mimic_diagnoses = pd.read_csv(diagnoses_file)\n",
    "    print(f\"Loaded {len(mimic_diagnoses)} MIMIC diagnosis records\")\n",
    "    display(mimic_diagnoses.head())\n",
    "\n",
    "# Load ICD codes dictionary\n",
    "mimic_icd = None\n",
    "if os.path.exists(icd_file):\n",
    "    mimic_icd = pd.read_csv(icd_file)\n",
    "    print(f\"Loaded {len(mimic_icd)} ICD code descriptions\")\n",
    "    display(mimic_icd.head())\n",
    "\n",
    "# Load lab results\n",
    "mimic_labs = None\n",
    "if os.path.exists(labs_file):\n",
    "    mimic_labs = pd.read_csv(labs_file)\n",
    "    print(f\"Loaded {len(mimic_labs)} lab result records\")\n",
    "    display(mimic_labs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare CDC Data for Classification\n",
    "\n",
    "Let's process the CDC data into a format suitable for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cdc_data(df):\n",
    "    \"\"\"\n",
    "    Process CDC data for classification.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Create target variable (1 for confirmed case, 0 for probable or missing)\n",
    "    result['covid_positive'] = result['current_status'].apply(\n",
    "        lambda x: 1 if x and 'confirmed' in str(x).lower() else 0\n",
    "    )\n",
    "    \n",
    "    # Handle missing values\n",
    "    for col in ['sex', 'age_group', 'hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']:\n",
    "        if col in result.columns:\n",
    "            result[col] = result[col].replace('Missing', np.nan)\n",
    "    \n",
    "    # Convert Yes/No columns to 1/0\n",
    "    for col in ['hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']:\n",
    "        if col in result.columns:\n",
    "            result[col] = result[col].map({'Yes': 1, 'No': 0, 'Unknown': np.nan})\n",
    "    \n",
    "    # Create dummy variables for categorical columns\n",
    "    if 'sex' in result.columns:\n",
    "        sex_dummies = pd.get_dummies(result['sex'], prefix='sex')\n",
    "        result = pd.concat([result, sex_dummies], axis=1)\n",
    "    \n",
    "    if 'age_group' in result.columns:\n",
    "        age_dummies = pd.get_dummies(result['age_group'], prefix='age')\n",
    "        result = pd.concat([result, age_dummies], axis=1)\n",
    "    \n",
    "    # Keep relevant columns only\n",
    "    cols_to_keep = ['covid_positive', 'hosp_yn', 'icu_yn', 'death_yn', 'medcond_yn']\n",
    "    \n",
    "    # Add dummy columns\n",
    "    cols_to_keep.extend([col for col in result.columns if col.startswith('sex_')])\n",
    "    cols_to_keep.extend([col for col in result.columns if col.startswith('age_')])\n",
    "    \n",
    "    # Filter to columns that exist\n",
    "    cols_to_keep = [col for col in cols_to_keep if col in result.columns]\n",
    "    \n",
    "    # Add record ID\n",
    "    result['record_id'] = ['CDC_' + str(i) for i in range(len(result))]\n",
    "    cols_to_keep.insert(0, 'record_id')  # Add to beginning\n",
    "    \n",
    "    # Return dataset with selected columns\n",
    "    return result[cols_to_keep]\n",
    "\n",
    "# Process CDC data\n",
    "cdc_processed = prepare_cdc_data(cdc_df)\n",
    "print(f\"Processed CDC data: {len(cdc_processed)} records with {len(cdc_processed.columns)} features\")\n",
    "cdc_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare MIMIC Data for Classification\n",
    "\n",
    "Now let's process the MIMIC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mimic_data(patients, diagnoses, icd_codes, labs):\n",
    "    \"\"\"\n",
    "    Process MIMIC data for classification.\n",
    "    \"\"\"\n",
    "    if patients is None:\n",
    "        return None\n",
    "    \n",
    "    # Start with patient data\n",
    "    result = patients.copy()\n",
    "    \n",
    "    # Add COVID-19 flag based on diagnoses if available\n",
    "    if diagnoses is not None and icd_codes is not None:\n",
    "        # Merge diagnoses with ICD codes\n",
    "        merged = pd.merge(diagnoses, icd_codes, on='icd_code', how='left')\n",
    "        \n",
    "        # Find COVID-related diagnoses\n",
    "        covid_codes = merged[merged['long_title'].str.contains('COVID|coronavirus|SARS-CoV', \n",
    "                                                         case=False, na=False)]\n",
    "        \n",
    "        # Get patients with COVID diagnoses\n",
    "        covid_patients = covid_codes['subject_id'].unique()\n",
    "        \n",
    "        # Add flag to result\n",
    "        result['covid_positive'] = result['subject_id'].isin(covid_patients).astype(int)\n",
    "        print(f\"Found {len(covid_patients)} patients with COVID-19 diagnoses\")\n",
    "    else:\n",
    "        # If no diagnoses data, assume all negative\n",
    "        result['covid_positive'] = 0\n",
    "        print(\"No diagnoses data available, assuming all patients are COVID-19 negative\")\n",
    "    \n",
    "    # Add lab data if available\n",
    "    if labs is not None:\n",
    "        try:\n",
    "            # Create pivot table with lab results\n",
    "            lab_pivot = labs.pivot_table(\n",
    "                index='subject_id',\n",
    "                columns='itemid',\n",
    "                values='valuenum',\n",
    "                aggfunc='mean'\n",
    "            )\n",
    "            \n",
    "            # Rename columns\n",
    "            lab_pivot.columns = [f'lab_{col}' for col in lab_pivot.columns]\n",
    "            lab_pivot.reset_index(inplace=True)\n",
    "            \n",
    "            # Merge with patient data\n",
    "            result = pd.merge(result, lab_pivot, on='subject_id', how='left')\n",
    "            print(f\"Added {len(lab_pivot.columns)-1} lab features\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding lab data: {e}\")\n",
    "    \n",
    "    # Process demographic features\n",
    "    if 'gender' in result.columns:\n",
    "        # Create dummy variables\n",
    "        gender_dummies = pd.get_dummies(result['gender'], prefix='gender')\n",
    "        result = pd.concat([result, gender_dummies], axis=1)\n",
    "    \n",
    "    # Create record ID\n",
    "    result['record_id'] = ['MIMIC_' + str(id) for id in result['subject_id']]\n",
    "    \n",
    "    # Select columns to keep\n",
    "    cols_to_keep = ['record_id', 'covid_positive']\n",
    "    \n",
    "    # Add demographic columns\n",
    "    gender_cols = [col for col in result.columns if col.startswith('gender_')]\n",
    "    cols_to_keep.extend(gender_cols)\n",
    "    \n",
    "    # Add lab columns\n",
    "    lab_cols = [col for col in result.columns if col.startswith('lab_')]\n",
    "    cols_to_keep.extend(lab_cols)\n",
    "    \n",
    "    # Select columns that exist\n",
    "    cols_to_keep = [col for col in cols_to_keep if col in result.columns]\n",
    "    \n",
    "    return result[cols_to_keep]\n",
    "\n",
    "# Process MIMIC data if available\n",
    "mimic_processed = None\n",
    "if mimic_patients is not None:\n",
    "    mimic_processed = prepare_mimic_data(mimic_patients, mimic_diagnoses, mimic_icd, mimic_labs)\n",
    "    print(f\"Processed MIMIC data: {len(mimic_processed)} records with {len(mimic_processed.columns)} features\")\n",
    "    display(mimic_processed.head())\n",
    "else:\n",
    "    print(\"No MIMIC patient data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Master Classification Dataset\n",
    "\n",
    "Now let's combine both datasets into a master classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets to combine\n",
    "datasets = []\n",
    "\n",
    "if cdc_processed is not None:\n",
    "    datasets.append(cdc_processed)\n",
    "    print(f\"Adding {len(cdc_processed)} CDC records\")\n",
    "\n",
    "if mimic_processed is not None:\n",
    "    datasets.append(mimic_processed)\n",
    "    print(f\"Adding {len(mimic_processed)} MIMIC records\")\n",
    "\n",
    "# Combine datasets\n",
    "if datasets:\n",
    "    master_df = pd.concat(datasets, axis=0, ignore_index=True)\n",
    "    print(f\"Created master dataset with {len(master_df)} records and {len(master_df.columns)} features\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    display(master_df.head())\n",
    "    \n",
    "    # Save to file\n",
    "    master_file = '../data/processed/covid_classification_dataset.csv'\n",
    "    master_df.to_csv(master_file, index=False)\n",
    "    print(f\"Saved master dataset to {master_file}\")\n",
    "else:\n",
    "    print(\"No data available to create master dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Master Dataset\n",
    "\n",
    "Let's examine the features and target distribution in our master dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'master_df' in locals() and master_df is not None:\n",
    "    # Target distribution\n",
    "    print(\"COVID-19 Status Distribution:\")\n",
    "    covid_dist = master_df['covid_positive'].value_counts()\n",
    "    display(covid_dist)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x='covid_positive', data=master_df)\n",
    "    plt.title('COVID-19 Positive vs Negative Cases')\n",
    "    plt.xlabel('COVID-19 Status (1=Positive, 0=Negative)')\n",
    "    plt.show()\n",
    "    \n",
    "    # Check missing values\n",
    "    missing = master_df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    \n",
    "    if not missing.empty:\n",
    "        print(\"\\nMissing values:\")\n",
    "        display(missing)\n",
    "        \n",
    "        # Plot missing values percentages\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        missing_pct = (missing / len(master_df) * 100).sort_values(ascending=False)\n",
    "        sns.barplot(x=missing_pct.values, y=missing_pct.index)\n",
    "        plt.title('Percentage of Missing Values')\n",
    "        plt.xlabel('% Missing')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nNo missing values in the dataset!\")\n",
    "    \n",
    "    # Check numeric correlations with target\n",
    "    numeric_cols = master_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr = master_df[numeric_cols].corr()['covid_positive'].sort_values(ascending=False)\n",
    "        print(\"\\nFeature correlations with COVID-19 status:\")\n",
    "        display(corr)\n",
    "        \n",
    "        # Plot correlations\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        corr = corr[corr.index != 'covid_positive']  # Remove self-correlation\n",
    "        top_corr = corr.head(15)  # Show top 15\n",
    "        sns.barplot(x=top_corr.values, y=top_corr.index)\n",
    "        plt.title('Top Feature Correlations with COVID-19')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Check class balance\n",
    "    class_balance = master_df['covid_positive'].value_counts(normalize=True) * 100\n",
    "    print(f\"\\nClass balance: {class_balance[1]:.1f}% positive, {class_balance[0]:.1f}% negative\")\n",
    "    \n",
    "    # Suggest balance handling if needed\n",
    "    if abs(class_balance[0] - class_balance[1]) > 20:\n",
    "        print(\"\\nNote: The dataset is imbalanced. Consider using class weights, sampling techniques,\")\n",
    "        print(\"or specialized metrics when training classification models.\")\n",
    "else:\n",
    "    print(\"No master dataset available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Basic Model Example (Optional) \n",
    "\n",
    "Here's a simple model demonstration, but only run this if you have scikit-learn installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    if 'master_df' in locals() and master_df is not None:\n",
    "        # Prepare features and target\n",
    "        X = master_df.drop(['record_id', 'covid_positive'], axis=1)\n",
    "        y = master_df['covid_positive']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Create pipeline with imputer and model\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "        ])\n",
    "        \n",
    "        # Train model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Evaluate\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "        \n",
    "        # Feature importance\n",
    "        if hasattr(pipeline.named_steps['classifier'], 'feature_importances_'):\n",
    "            importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "            features = X_train.columns\n",
    "            \n",
    "            # Create DataFrame\n",
    "            importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "            importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "            \n",
    "            # Display top features\n",
    "            print(\"\\nTop 10 Important Features:\")\n",
    "            display(importance_df.head(10))\n",
    "            \n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x='Importance', y='Feature', data=importance_df.head(10))\n",
    "            plt.title('Feature Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Save feature importance\n",
    "            importance_df.to_csv('../data/processed/feature_importance.csv', index=False)\n",
    "            print(f\"Saved feature importance to ../data/processed/feature_importance.csv\")\n",
    "    else:\n",
    "        print(\"No master dataset available for modeling\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"scikit-learn not installed. Skip model training.\")\n",
    "    print(\"Install with: pip install scikit-learn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "In this notebook, we:\n",
    "1. Loaded and processed CDC Case Surveillance data\n",
    "2. Loaded and processed MIMIC-IV clinical data\n",
    "3. Combined them into a master classification dataset\n",
    "4. Analyzed features and relationships with COVID-19 status\n",
    "5. Created a simple demonstration model (if scikit-learn was available)\n",
    "\n",
    "The master dataset is now saved at `../data/processed/covid_classification_dataset.csv` and is ready for further model development.\n",
    "\n",
    "Next steps could include:\n",
    "- Feature engineering to create more predictive variables\n",
    "- Hyperparameter tuning for classification models\n",
    "- Integration with the NER pipeline to incorporate text-derived features\n",
    "- Deployment of the model in a production pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}