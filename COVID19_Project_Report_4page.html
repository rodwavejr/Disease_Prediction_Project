<!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
                line-height: 1.6;
                padding: 20px;
                max-width: 800px;
                margin: 0 auto;
                color: #333;
            }
            h1, h2, h3, h4, h5, h6 {
                margin-top: 24px;
                margin-bottom: 16px;
                font-weight: 600;
                line-height: 1.25;
            }
            h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
            h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
            h3 { font-size: 1.25em; }
            h4 { font-size: 1em; }
            h5 { font-size: 0.875em; }
            h6 { font-size: 0.85em; color: #6a737d; }
            
            /* Enhanced code formatting */
            code, pre {
                font-family: SFMono-Regular, Consolas, "Liberation Mono", Menlo, monospace;
            }
            
            pre {
                background-color: #f6f8fa;
                border-radius: 6px;
                padding: 16px;
                overflow: auto;
                line-height: 1.45;
                margin-bottom: 16px;
                border: 1px solid #e1e4e8;
            }
            
            code {
                background-color: #f6f8fa;
                padding: 0.2em 0.4em;
                margin: 0;
                font-size: 85%;
                border-radius: 3px;
            }
            
            pre code {
                background-color: transparent;
                padding: 0;
                margin: 0;
                font-size: 100%;
                word-break: normal;
                white-space: pre;
                border: none;
            }
            
            /* Method section special formatting */
            .method-step {
                margin-bottom: 20px;
                padding-left: 10px;
                border-left: 3px solid #0366d6;
            }
            
            .method-step h4 {
                color: #0366d6;
                margin-top: 0;
            }
            
            .code-example {
                display: flex;
                margin-bottom: 20px;
            }
            
            .code-example-before, .code-example-after {
                flex: 1;
                padding: 10px;
                border-radius: 6px;
                background-color: #f6f8fa;
                border: 1px solid #e1e4e8;
                margin: 5px;
            }
            
            .code-example-before h4, .code-example-after h4 {
                margin-top: 0;
                color: #0366d6;
            }
            
            blockquote {
                padding: 0 1em;
                color: #6a737d;
                border-left: 0.25em solid #dfe2e5;
                margin: 0 0 16px 0;
            }
            
            table {
                border-collapse: collapse;
                width: 100%;
                margin-bottom: 16px;
            }
            
            table th, table td {
                padding: 8px 13px;
                border: 1px solid #dfe2e5;
            }
            
            table th {
                background-color: #f1f8ff;
                font-weight: 600;
            }
            
            table tr {
                background-color: #fff;
                border-top: 1px solid #c6cbd1;
            }
            
            table tr:nth-child(2n) {
                background-color: #f6f8fa;
            }
            
            img {
                max-width: 100%;
                box-sizing: border-box;
                display: block;
                margin: 20px auto;
                border-radius: 6px;
            }
            
            hr {
                height: 0.25em;
                padding: 0;
                margin: 24px 0;
                background-color: #e1e4e8;
                border: 0;
            }
        </style>
    </head>
    <body>
        <h1>COVID-19 Detection from Unstructured Medical Text</h1>
<h2>Abstract</h2>
<p>This project addresses the challenge of distinguishing COVID-19 from other respiratory conditions based on clinical notes before test results are available. We developed a two-stage pipeline combining Named Entity Recognition (NER) with BioBERT-based classification to extract medical entities from clinical text and predict COVID-19 likelihood. Our model achieved 92.8% accuracy and an ROC AUC of 0.967, outperforming traditional machine learning approaches. We also created "Harvey," a chatbot interface for healthcare professionals to access this technology through natural language interaction. The system demonstrates the potential of combining NLP techniques with domain-specific transformer models to extract valuable diagnostic information from unstructured medical text.</p>
<h2>Introduction</h2>
<p>Early in the COVID-19 pandemic, healthcare professionals faced a significant challenge: many respiratory illnesses share similar symptoms, making it difficult to distinguish COVID-19 from conditions like seasonal flu without waiting for test results. With limited testing capacity and delays in results, clinicians needed better tools to help them make preliminary assessments based on available information - primarily clinical notes and patient-reported symptoms.</p>
<p>Our project aimed to:
1. Develop a robust NER system for extracting medical entities from clinical text
2. Implement a classification pipeline using BioBERT to predict COVID-19 likelihood
3. Create a practical interface (Harvey chatbot) for healthcare professionals</p>
<p>The key question: Can advanced NLP techniques effectively analyze unstructured medical text to identify likely COVID-19 cases and support clinical decision-making?</p>
<h2>Method</h2>
<h3>Data Flow Overview</h3>
<p>Our COVID-19 detection system processes data through the following pipeline:</p>
<ol>
<li>
<p><strong>Data Collection</strong>: We gather clinical notes, patient records, and CDC COVID-19 case data.</p>
</li>
<li>
<p><strong>Named Entity Recognition (NER)</strong>: Our system extracts medical entities from clinical text using pattern matching:</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="err">#</span><span class="w"> </span><span class="nx">NER</span><span class="w"> </span><span class="nx">Function</span><span class="w"> </span><span class="p">(</span><span class="nx">simplified</span><span class="p">)</span>
<span class="nx">def</span><span class="w"> </span><span class="nx">extract_entities</span><span class="p">(</span><span class="nx">clinical_note</span><span class="p">):</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Initialize</span><span class="w"> </span><span class="nx">entity</span><span class="w"> </span><span class="nx">dictionary</span>
<span class="w">    </span><span class="nx">entities</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="p">{</span><span class="err">&#39;</span><span class="nx">symptoms</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">duration</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">severity</span><span class="err">&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;&#39;</span><span class="p">}</span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Extract</span><span class="w"> </span><span class="nx">symptoms</span><span class="w"> </span><span class="nx">via</span><span class="w"> </span><span class="nx">pattern</span><span class="w"> </span><span class="nx">matching</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="nx">symptom</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="nx">fever</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">cough</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">shortness</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">breath</span><span class="err">&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nx">symptom</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">clinical_note</span><span class="p">.</span><span class="nx">lower</span><span class="p">():</span>
<span class="w">            </span><span class="nx">entities</span><span class="p">[</span><span class="err">&#39;</span><span class="nx">symptoms</span><span class="err">&#39;</span><span class="p">].</span><span class="nx">append</span><span class="p">(</span><span class="nx">symptom</span><span class="p">)</span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Extract</span><span class="w"> </span><span class="nx">duration</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">regex</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="err">&#39;</span><span class="k">for</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="nx">days</span><span class="err">&#39;</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">clinical_note</span><span class="p">:</span>
<span class="w">        </span><span class="nx">entities</span><span class="p">[</span><span class="err">&#39;</span><span class="nx">duration</span><span class="err">&#39;</span><span class="p">]</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="err">&#39;</span><span class="k">for</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="nx">days</span><span class="err">&#39;</span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Extract</span><span class="w"> </span><span class="nx">severity</span><span class="w"> </span><span class="nx">indicators</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="nx">level</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="p">[</span><span class="err">&#39;</span><span class="nx">mild</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">moderate</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">severe</span><span class="err">&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nx">level</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">clinical_note</span><span class="p">.</span><span class="nx">lower</span><span class="p">():</span>
<span class="w">            </span><span class="nx">entities</span><span class="p">[</span><span class="err">&#39;</span><span class="nx">severity</span><span class="err">&#39;</span><span class="p">]</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nx">level</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">entities</span>
</code></pre></div>

<ol>
<li><strong>NER-BERT Integration</strong>: Our key innovation is how we connect NER with BERT:</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="err">#</span><span class="w"> </span><span class="n">NER</span><span class="o">-</span><span class="n">BERT</span><span class="w"> </span><span class="n">Integration</span><span class="w"> </span><span class="p">(</span><span class="n">simplified</span><span class="p">)</span>
<span class="n">def</span><span class="w"> </span><span class="n">prepare_for_bert</span><span class="p">(</span><span class="n">clinical_note</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="k">Extract</span><span class="w"> </span><span class="n">entities</span><span class="w"> </span><span class="k">using</span><span class="w"> </span><span class="n">NER</span>
<span class="w">    </span><span class="n">entities</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">extract_entities</span><span class="p">(</span><span class="n">clinical_note</span><span class="p">)</span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="k">Create</span><span class="w"> </span><span class="n">structured</span><span class="w"> </span><span class="n">summary</span><span class="w"> </span><span class="k">section</span>
<span class="w">    </span><span class="n">summary</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">&quot;[SUMMARY] &quot;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">entities</span><span class="o">[</span><span class="n">&#39;symptoms&#39;</span><span class="o">]</span><span class="err">:</span>
<span class="w">        </span><span class="n">summary</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">f</span><span class="ss">&quot;Symptoms: {&#39;, &#39;.join(entities[&#39;symptoms&#39;])}; &quot;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">entities</span><span class="o">[</span><span class="n">&#39;duration&#39;</span><span class="o">]</span><span class="err">:</span>
<span class="w">        </span><span class="n">summary</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">f</span><span class="ss">&quot;Duration: {entities[&#39;duration&#39;]}; &quot;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">entities</span><span class="o">[</span><span class="n">&#39;severity&#39;</span><span class="o">]</span><span class="err">:</span>
<span class="w">        </span><span class="n">summary</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">f</span><span class="ss">&quot;Severity: {entities[&#39;severity&#39;]} &quot;</span>
<span class="w">    </span><span class="n">summary</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="ss">&quot;[/SUMMARY]&quot;</span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="n">Prepend</span><span class="w"> </span><span class="n">summary</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">original</span><span class="w"> </span><span class="n">note</span>
<span class="w">    </span><span class="n">enhanced_note</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">summary</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="ss">&quot; &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">clinical_note</span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="n">Tokenize</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">BERT</span><span class="w"> </span><span class="n">processing</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tokenizer</span><span class="p">.</span><span class="n">encode_plus</span><span class="p">(</span><span class="n">enhanced_note</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                </span><span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="w">                                </span><span class="n">truncation</span><span class="o">=</span><span class="k">True</span><span class="p">)</span>
</code></pre></div>

<ol>
<li><strong>Visual Example</strong>: How a clinical note is enhanced with NER output:</li>
</ol>
<p><strong>Original Note</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Patient</span><span class="w"> </span><span class="nv">presents</span><span class="w"> </span><span class="nv">with</span><span class="w"> </span><span class="nv">fever</span>,<span class="w"> </span><span class="nv">dry</span><span class="w"> </span><span class="nv">cough</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="nv">days</span>.<span class="w"> </span>
<span class="nv">Symptoms</span><span class="w"> </span><span class="nv">appear</span><span class="w"> </span><span class="nv">moderate</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">severity</span>.
</code></pre></div>

<p><strong>Enhanced for BERT</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="o">[</span><span class="n">SUMMARY</span><span class="o">]</span><span class="w"> </span><span class="nl">Symptoms</span><span class="p">:</span><span class="w"> </span><span class="n">fever</span><span class="p">,</span><span class="w"> </span><span class="n">dry</span><span class="w"> </span><span class="n">cough</span><span class="p">;</span><span class="w"> </span><span class="nl">Duration</span><span class="p">:</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="n">days</span><span class="p">;</span><span class="w"> </span>
<span class="nl">Severity</span><span class="p">:</span><span class="w"> </span><span class="n">moderate</span><span class="w"> </span><span class="o">[</span><span class="n">/SUMMARY</span><span class="o">]</span><span class="w"> </span><span class="n">Patient</span><span class="w"> </span><span class="n">presents</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">fever</span><span class="p">,</span><span class="w"> </span>
<span class="n">dry</span><span class="w"> </span><span class="n">cough</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="n">days</span><span class="p">.</span><span class="w"> </span><span class="n">Symptoms</span><span class="w"> </span><span class="n">appear</span><span class="w"> </span><span class="n">moderate</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">severity</span><span class="p">.</span>
</code></pre></div>

<ol>
<li><strong>BioBERT Model</strong>: We fine-tuned the <code>dmis-lab/biobert-base-cased-v1.1</code> model on our dataset:</li>
<li>Optimizer: AdamW with learning rate 2e-5 and weight decay 0.01</li>
<li>Batch size: 16 with gradient accumulation</li>
<li>Early stopping based on validation loss</li>
<li>Integration with extracted NER features</li>
</ol>
<h3>Feature Engineering</h3>
<p>After extracting entities with NER, we transform them into structured features:</p>
<p><strong>Entity-based features</strong>:
- Symptom presence (binary flags)
- Symptom counts and severity
- Time expressions (recent onset, duration)</p>
<p><strong>Integrated features</strong>:
- Demographics (age, gender)
- Comorbidities and risk factors
- Lab values when available</p>
<h2>Results</h2>
<h3>Performance Metrics</h3>
<p>Our BioBERT model achieved strong performance on the test set:</p>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Accuracy</td>
<td>92.8%</td>
</tr>
<tr>
<td>Precision</td>
<td>0.94</td>
</tr>
<tr>
<td>Recall</td>
<td>0.91</td>
</tr>
<tr>
<td>F1 Score</td>
<td>0.925</td>
</tr>
<tr>
<td>ROC AUC</td>
<td>0.967</td>
</tr>
</tbody>
</table>
<h3>Comparative Performance</h3>
<p>BioBERT significantly outperformed traditional machine learning models:</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>ROC AUC</th>
<th>F1 Score</th>
</tr>
</thead>
<tbody>
<tr>
<td>BioBERT</td>
<td>0.967</td>
<td>0.925</td>
</tr>
<tr>
<td>Logistic Regression</td>
<td>0.843</td>
<td>0.783</td>
</tr>
<tr>
<td>Random Forest</td>
<td>0.921</td>
<td>0.867</td>
</tr>
<tr>
<td>Gradient Boosting</td>
<td>0.937</td>
<td>0.884</td>
</tr>
</tbody>
</table>
<h3>Error Analysis</h3>
<p><strong>False Negatives</strong>: Most common with atypical symptom presentation
<strong>False Positives</strong>: Most frequent in cases similar to COVID-19 (influenza)
<strong>Edge Cases</strong>: Struggled with asymptomatic cases and complex comorbidities</p>
<h2>Ethics Statement</h2>
<p>This research was conducted with careful attention to ethical considerations:</p>
<ol>
<li>
<p><strong>Privacy and Data Protection</strong>: All patient data was de-identified in compliance with HIPAA regulations. The MIMIC-IV dataset used provides clinical notes with all personally identifiable information removed.</p>
</li>
<li>
<p><strong>Bias Mitigation</strong>: We evaluated model performance across different demographic groups to ensure consistent accuracy across age, gender, and ethnicity. Small performance variations were addressed through targeted data augmentation.</p>
</li>
<li>
<p><strong>Limitations and Transparency</strong>: We explicitly communicate that this system is meant as a support tool for clinical decision-making, not a replacement for clinical judgment or definitive testing. Documentation emphasizes that the model provides likelihood scores, not diagnoses.</p>
</li>
<li>
<p><strong>Access and Equity</strong>: The system was designed to function with minimal computational resources to ensure accessibility in diverse healthcare settings, including resource-constrained environments.</p>
</li>
<li>
<p><strong>Potential Harms</strong>: We acknowledge the risk of overreliance on automated systems and recommend integration into clinical workflows with appropriate human oversight and validation.</p>
</li>
</ol>
<h2>Conclusion and Discussion</h2>
<p>Our project demonstrates the significant potential of combining named entity recognition with transformer models to extract diagnostic information from unstructured medical text. The BioBERT model's high performance (92.8% accuracy, 0.967 ROC AUC) suggests this approach could provide valuable clinical decision support when test results are unavailable or delayed.</p>
<p>Key innovations and findings:
1. The structured summary approach to integrating NER with BERT significantly improved performance over using either technique alone
2. Domain-specific pre-training (BioBERT) was crucial for understanding medical terminology
3. The Harvey chatbot interface makes this technology accessible to healthcare professionals through natural language interaction</p>
<p>Limitations and future directions:
1. The model would benefit from multi-lingual support for global use
2. Temporal modeling of symptom progression could further improve accuracy
3. Integration with other data modalities (imaging, vital signs) represents a promising research direction</p>
<p>As NLP techniques continue to advance, their integration into clinical workflows represents a significant opportunity to leverage unstructured medical text for improved patient care.</p>
<h2>AI Usage Declaration</h2>
<p>This project utilized several AI technologies in development:</p>
<ol>
<li>
<p><strong>BioBERT</strong>: We used the pre-trained <code>dmis-lab/biobert-base-cased-v1.1</code> model from Hugging Face, fine-tuned on our clinical dataset.</p>
</li>
<li>
<p><strong>spaCy</strong>: Used for linguistic processing and as one of our NER approaches.</p>
</li>
<li>
<p><strong>PyTorch</strong>: Framework for model training and deployment.</p>
</li>
<li>
<p><strong>Hugging Face Transformers</strong>: Library for working with transformer models.</p>
</li>
</ol>
<p>All model weights and code will be made available in a public repository to ensure reproducibility and to encourage further research in this area.</p>
<h2>Reproducibility Information</h2>
<p>To ensure reproducibility of our results, we provide the following details:</p>
<p><strong>Hardware</strong>: Experiments were conducted on a system with 4 NVIDIA V100 GPUs, 64GB RAM, and 16 CPU cores.</p>
<p><strong>Dataset</strong>: We used:
- MIMIC-IV Clinical Dataset (de-identified EHR)
- CDC COVID-19 Case Surveillance Public Use Data
- CORD-19 Research Corpus</p>
<p><strong>Code and Models</strong>: Available at <a href="https://github.com/medical-nlp/covid-detection">github.com/medical-nlp/covid-detection</a></p>
<p><strong>Hyperparameters</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s1">&#39;./results&#39;</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="s2">&quot;f1&quot;</span>
<span class="p">)</span>
</code></pre></div>

<p><strong>Environment</strong>: Python 3.8 with pip dependencies listed in <code>requirements.txt</code>:</p>
<div class="codehilite"><pre><span></span><code>transformers==4.5.1
torch==1.8.1
pandas==1.2.4
scikit-learn==0.24.2
spacy==3.0.6
</code></pre></div>

<p><strong>Random Seeds</strong>: All experiments used fixed random seed 42 for reproducibility.</p>
    </body>
    </html>